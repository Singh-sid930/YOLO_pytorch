# -*- coding: utf-8 -*-
"""Siddharth_CIS680_Fall2019_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bzl44i6sTP_xsxBv_iAdH7hCSeFcjTZ1

# Google Drive

This first code block attaches your google drive and makes a folder structure. You only need to run this when a new VM is assigned to you. To get your code as a single python file go through the following menus File->'Download .py'.

This also downloads 2 npz files for your use: labels.npz and images.npz. For those not using colab you can download manually here:

https://drive.google.com/open?id=1jIKQLhTHZUE6m2mE5lRKMSqN7ZGK2Gyu

https://drive.google.com/open?id=1Gth_AVG5t-4ZhH_whOaXwe0PBXNhIIK0
"""

from google.colab import drive
drive.mount('/content/drive')

import os
from google.colab import drive

# Mount google drive
DRIVE_MOUNT='/content/gdrive'
drive.mount(DRIVE_MOUNT)


# create folder to write data to
CIS680_FOLDER=os.path.join(DRIVE_MOUNT, 'My Drive', 'CIS680_2019')
HOMEWORK_FOLDER=os.path.join(CIS680_FOLDER, 'HW2')
os.makedirs(HOMEWORK_FOLDER, exist_ok=True)

# bootstrap environment into place
from google.colab import auth
auth.authenticate_user()

from googleapiclient.discovery import build
drive_service = build('drive', 'v3')

import io
import os
from googleapiclient.http import MediaIoBaseDownload

def download_file(fn, file_id):
    request = drive_service.files().get_media(fileId=file_id)
    downloaded = io.BytesIO()
    downloader = MediaIoBaseDownload(downloaded, request)
    done = False
    while done is False:
        # _ is a placeholder for a progress object that we ignore.
        # (Our file is small, so we skip reporting progress.)
        _, done = downloader.next_chunk()
    
    downloaded.seek(0)

    folder = fn.split('/')
    if len(folder) > 1:
        os.makedirs(folder[0], exist_ok=True)

    with open(fn, 'wb') as f:
        f.write(downloaded.read())

id_to_fn = {
    '1Gth_AVG5t-4ZhH_whOaXwe0PBXNhIIK0': 'labels.npz',
    '1jIKQLhTHZUE6m2mE5lRKMSqN7ZGK2Gyu': 'images.npz'
           }

# download all files into the vm
for fid, fn in id_to_fn.items():
    download_file(fn, fid)

"""# PyTorch Dataset

Here you will implement a simple pytorch dataset that loads the images and labels as describe in the PDF.
"""

# torch and torchvision imports
import torch
import torchvision
import numpy as np 


class HW2TrainDataset(torch.utils.data.Dataset):
  def __init__(self, path):
    images = np.load('/content/images.npz')
    images = images["arr_0"]
    self.images_train = images[0:9000]
    

    labels = np.load('/content/labels.npz',allow_pickle = True, encoding = "latin1")
    labels = labels["arr_0"]
    self.labels_train = labels[0:9000]
  
  def convertLabel(self,labels):
    
    ground_truth = np.zeros((8,8,8))
    
    for label in labels:
      
      width = label[3] - label[1]
      height = label[4] - label[2]
      
      object_class = label[0]
      
      x_c = label[1] + width/2
      y_c = label[2] + height/2

      x_i = int((x_c/16))
      y_i = int((y_c/16))

      ground_truth[0][y_i][x_i] = 1
      ground_truth[1][y_i][x_i] = (x_c- (x_i * 16))/16
      ground_truth[2][y_i][x_i] = (y_c- (y_i * 16))/16
      ground_truth[3][y_i][x_i] = float(width/128)
      ground_truth[4][y_i][x_i] = float(height/128)
      ground_truth[5][y_i][x_i] = (object_class == 0)
      ground_truth[6][y_i][x_i] = (object_class == 1)
      ground_truth[7][y_i][x_i] = (object_class == 2)
    return ground_truth

    
  def __getitem__(self, index):
    
    image = self.images_train[index]
    image = image.transpose((2,0,1))
    image = torch.tensor(image).type(torch.FloatTensor)
    label = torch.tensor(self.convertLabel(self.labels_train[index]))
    
    return image,label
  
  def __len__(self):
    return len(self.images_train)
    

class HW2TestDataset(torch.utils.data.Dataset):
  def __init__(self, path):
    images = np.load('/content/images.npz')
    images = images["arr_0"]
    self.images_test = images[9000:10000]

    labels = np.load('/content/labels.npz',allow_pickle = True, encoding = "latin1")
    labels = labels["arr_0"]
    self.labels_test = labels[9000:10000]
    
  def convertLabel(self,labels):
    ground_truth = np.zeros((8,8,8))
    for label in labels:
      width = label[3] - label[1]
      height = label[4] = label[2]
      object_class = label[0]
      x_c = label[1] + width/2
      y_c = label[2] + height/2

      x_i = int((x_c/16))
      y_i = int((y_c/16))
      ground_truth[0][y_i][x_i] = 1
      ground_truth[1][y_i][x_i] = (x_c - (x_i * 16))/16
      ground_truth[2][y_i][x_i] = (y_c - (y_i * 16))/16
      ground_truth[3][y_i][x_i] = float(width/128)
      ground_truth[4][y_i][x_i] = float(height/128)
      ground_truth[5][y_i][x_i] = (object_class == 0)
      ground_truth[6][y_i][x_i] = (object_class == 1)
      ground_truth[7][y_i][x_i] = (object_class == 2)
      
    return ground_truth
  
    
  def __len__(self):
    return len(self.images_test)
  

    
  def __getitem__(self, index):
    image = self.images_test[index]
#     print(image.transpose((2, 0, 1).shape))
    image = torch.tensor(image.transpose((2, 0, 1))).type(torch.FloatTensor)
    label = torch.tensor(self.convertLabel(self.labels_test[index]))
    
    return image,label

"""# Dataset test

The data set class can be tested here.
"""

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

train_dataset = HW2TrainDataset(None)
image,label = train_dataset.__getitem__(15)
print(image.shape)
image = image.type(torch.IntTensor).numpy()
image = np.transpose(image,(1,2,0))
fig,ax = plt.subplots(1)
ax.imshow(image)

label = label.numpy()

for i in range(8):
  for j in range(8):
    if label[0][i][j]>0.5:
      if label[5][i][j]>0.5:
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 -width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect1 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='r',facecolor='none')
        ax.add_patch(rect1)
      if label[6][i][j]>0.5:
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect2 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='b',facecolor='none')
        ax.add_patch(rect2)
      if label[7][i][j]>0.5:
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect3 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='g',facecolor='none')
        ax.add_patch(rect3)
        
        
plt.show()

"""# Model Definition"""

import torch
import torch.nn as nn 
from torch.autograd import Variable
import torch.nn.functional as F 


class YOLOish(torch.nn.Module):
  def __init__(self):
    super(YOLOish,self).__init__()
    self.cn1 = nn.Conv2d(3,32,kernel_size = 4,stride = 2, padding = 1)
    self.cn1_bn = nn.BatchNorm2d(32)
    self.cn2 = nn.Conv2d(32,64,kernel_size = 4,stride = 2, padding = 1)
    self.cn2_bn = nn.BatchNorm2d(64)
    self.cn3 = nn.Conv2d(64,128,kernel_size = 4,stride = 2, padding = 1)
    self.cn3_bn = nn.BatchNorm2d(128)
    self.cn4 = nn.Conv2d(128,256,kernel_size = 4,stride = 2, padding = 1)
    self.cn4_bn = nn.BatchNorm2d(256)
    self.cn5 = nn.Conv2d(256,512,kernel_size = 4,stride = 2, padding = 1)
    self.cn5_bn = nn.BatchNorm2d(512)
    self.cn6 = nn.Conv2d(512,1024,kernel_size = 4,stride = 2, padding = 1)
    self.cn6_bn = nn.BatchNorm2d(1024)
    self.cn7 = nn.ConvTranspose2d(1024,256,kernel_size = 4,stride = 2, padding = 1)
    self.cn7_bn = nn.BatchNorm2d(256)
    self.cn8 = nn.ConvTranspose2d(256,64,kernel_size = 4,stride = 2, padding = 1)
    self.cn8_bn = nn.BatchNorm2d(64)
    self.cn9 = nn.Conv2d(64,8,kernel_size = 3,stride = 1, padding = 1)
    

    
  def forward(self, X):
    x = self.cn1(X)
    x = F.relu(self.cn1_bn(x))
    x = self.cn2(x)
    x = F.relu(self.cn2_bn(x))
    x = self.cn3(x)
    x = F.relu(self.cn3_bn(x))
    x = self.cn4(x)
    x = F.relu(self.cn4_bn(x))
    x = self.cn5(x)
    x = F.relu(self.cn5_bn(x))
    x = self.cn6(x)
    x = F.relu(self.cn6_bn(x))
    x = self.cn7(x)
    x = F.relu(self.cn7_bn(x))
    x = self.cn8(x)
    x = F.relu(self.cn8_bn(x))
    x = self.cn9(x)
    x = F.sigmoid(x)
    return x

"""# Train your network

Training the network
"""

import torch
import torch.nn as nn 
from torch.autograd import Variable
import torch.nn.functional as F 
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms 
import numpy as np 
import matplotlib.pyplot as plt


net = YOLOish().cuda()

train_loader = torch.utils.data.DataLoader(dataset=HW2TrainDataset(None),batch_size = 16, shuffle = True)
test_loader = torch.utils.data.DataLoader(dataset=HW2TestDataset(None),batch_size = 16, shuffle = True)

optimizer = optim.Adam(net.parameters(), lr = 0.01)


def criterion(ouput,target):
  
  coordinate_loss = 0
  dimension_loss = 0 
  objectness_loss = 0
  background_loss = 0
  object_class_loss = 0
  lambda_coord = 5
  lambda_nobj = 0.5
  
  ouput = ouput.type(torch.DoubleTensor).cuda()
  objectness = (target[:,0]==1.0).type(torch.DoubleTensor).cuda()
  nobjectness = (~(target[:,0]==1.0)).type(torch.DoubleTensor).cuda()
  coordinate_loss = torch.sum(objectness*((target[:,1]-ouput[:,1])**2) + objectness*((target[:,2]-ouput[:,2])**2))
  dimension_loss = torch.sum(objectness*((target[:,3]**(1/2)-ouput[:,3]**(1/2))**2) + objectness*((target[:,4]**(1/2)-ouput[:,4]**(1/2))**2))
  objectness_loss =  torch.sum(objectness*((target[:,0]-ouput[:,0])**2))
  background_loss =  torch.sum((nobjectness)*((target[:,0]-ouput[:,0])**2))
  object_class_loss = torch.sum(objectness*(((target[:,5]-ouput[:,5])**2)+((target[:,6]-ouput[:,6])**2)+((target[:,7]-ouput[:,7])**2)))
  
  loss = lambda_coord * (coordinate_loss + dimension_loss) + objectness_loss + lambda_nobj*background_loss + object_class_loss
  return loss

def iou(output,target,i,j):
  
  axmin = output[1]*16 + 16*j - (output[3]*128)/2
  axmax = output[1]*16 + 16*j + (output[3]*128)/2
  aymin = output[2]*16 + 16*i - (output[4]*128)/2
  aymax = output[2]*16 + 16*i + (output[4]*128)/2
  awidth = output[3]*128
  aheight = output[4]*128
  aarea = awidth*aheight
  
  bxmin = target[1]*16 + 16*j - (target[3]*128)/2
  bxmax = target[1]*16 + 16*j + (target[3]*128)/2
  bymin = target[2]*16 + 16*i - (target[4]*128)/2
  bymax = target[2]*16 + 16*i + (target[4]*128)/2
  bwidth = target[3]*128
  bheight = target[4]*128
  barea = bwidth*bheight

  aibw = max(0,min(axmax,bxmax)-max(axmin,bxmin))
  aibh = max(0,min(aymax,bymax)-max(aymin,bymin))
  aib = aibw*aibh
  aub = aarea + barea - aib 
  iou = aib/aub
  return iou
  

def map(output,target):
  output_check = output.detach().cpu().numpy().copy()
  target_check = target.detach().cpu().numpy().copy()
  total_correct = 0.0
  correct = 0.0
  correct_p = 0.0
  correct_v = 0.0
  correct_t = 0.0
  total_correct_p = 1.0
  total_correct_v = 1.0
  total_correct_t = 1.0
  for b in range(16):
    for i in range(8):
        for j in range(8):
          if target_check[b][0][i][j] == 1:
            total_correct+=1.0
            if target_check[b][5][i][j] == 1:
              total_correct_p +=1
            if target_check[b][6][i][j] == 1:
              total_correct_t +=1
            if target_check[b][7][i][j] == 1:
              total_correct_v +=1
            class1 = output_check[b][5][i][j]
            class2 = output_check[b][6][i][j]
            class3 = output_check[b][7][i][j]
            index = [class1,class2,class3].index(max([class1,class2,class3]))
            classification = False
            iou_val = False
            output_compare = [output_check[b][0][i][j],output_check[b][1][i][j],output_check[b][2][i][j],output_check[b][3][i][j],output_check[b][4][i][j]] 
            target_compare = [target_check[b][0][i][j],target_check[b][1][i][j],target_check[b][2][i][j],target_check[b][3][i][j],target_check[b][4][i][j]] 
            iou_rat = iou(output_compare,target_compare,i,j)
#             print(" iou value is : ", iou_rat)
            if (target[b][5+index][i][j]==1):
#               print("correctly classified")
              classification = True
              if index==0:
                correct_p+=1
              if index==1:
                correct_t+=1
              if index==2:
                correct_v+=1
            if (iou_rat>0.5):
#               print("correctly localized")
              iou_val = True
            if(classification and iou_val):
              correct+=1.0
              return (correct/total_correct),(correct_p/total_correct_p),(correct_t/total_correct_t),(correct_v/total_correct_v)
            return 0.0,0.0,0.0,0.0
  
  

def train(model, train_loader, optimizer, epoch):
    model.train()
    accuracy  = 0.0
    accuracy_p  = 0.0
    accuracy_t  = 0.0
    accuracy_v  = 0.0
    loss_vals  = []
    train_loss = 0
    i = 0
    for batch_idx, (data, target) in enumerate(train_loader):
        i+=1
        data, target = data.cuda(), target.cuda()
        optimizer.zero_grad()
        output = model(data)
#         loss = 0
        loss = criterion(output, target)
        loss.backward()
        train_loss = train_loss + (loss.item()/16)
        optimizer.step()
        accuracy_o,accuracy_p_o,accuracy_t_o,accuracy_v_o = map(output,target)
        accuracy = accuracy + accuracy_o
        accuracy_p = accuracy_p + accuracy_p_o
        accuracy_t = accuracy_t + accuracy_t_o
        accuracy_v = accuracy_v + accuracy_v_o
        if batch_idx % 10 == 0:
          print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * len(data), len(train_loader.dataset),
                100. * batch_idx / len(train_loader),loss.item()))
          print("train map is :", accuracy/i)
    return train_loss/9000,accuracy/i,accuracy_p/i,accuracy_t/i,accuracy_v/i

def test(model,criterion, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    act_correct = 0
    acc_vals = []
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.cuda(), target.cuda()
            output = model(data)
            test_loss += criterion(output, target).item() # sum up batch loss
          
            pred = torch.zeros((1,3,8,8)).type(torch.DoubleTensor).cuda()
            for i in range(8):
              for j in range(8):
                if target[0][0][i][j] == 1:
                  class1 = output[0][5][i][j]
                  class2 = output[0][6][i][j]
                  class3 = output[0][7][i][j]
                  index = [class1,class2,class3].index(max([class1,class2,class3]))
                  pred[0][index][i][j] = 1
            correct +=torch.sum(pred*target[:][0][5:])
            act_correct +=torch.sum(target[:][0][5:])
            
    test_loss /= len(test_loader.dataset)
    accuracy = correct.item()/act_correct.item()    
    print("loss is = ", test_loss, "and accuracy is = ", accuracy )
    return test_loss,accuracy
            
                  
                  

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))
    return test_loss,correct/len(test_loader.dataset)

  
num_epochs = 50
train_loss_list = []
acc_val_train = []
acc_val_train_p = []
acc_val_train_t = []
acc_val_train_v = []

loss_val_test = []
acc_val_test = []

plt.figure()

for epoch in range(num_epochs):
  loss_vals,acc,acc_p,acc_t,acc_v= train(net, train_loader, optimizer, epoch)
#   break
  train_loss_list.append(loss_vals)
  acc_val_train.append(acc)
  acc_val_train_p.append(acc_p)
  acc_val_train_t.append(acc_t)
  acc_val_train_v.append(acc_v)
  test_loss,acc_vals = test( net,criterion, test_loader)
  loss_val_test.append(test_loss)
  acc_val_test.append(acc_vals)
  f1 = plt.figure(1)
  plt.plot(list(train_loss_list),marker = 'o')
  plt.xlabel("epochs")
  plt.ylabel("Train loss value ")
  plt.title(" Train Loss Curve ")
  f1.show()
  f2 = plt.figure(2)
  plt.plot(list(acc_val_train),marker = 'o')
  plt.xlabel("epochs")
  plt.ylabel("Train map value ")
  plt.title(" Train map Curve ")
  f2.show()
  f3 = plt.figure(3)
  plt.plot(list(acc_val_train_p),marker = 'o')
  plt.xlabel("epochs")
  plt.ylabel("Train map value ")
  plt.title(" Train map Curve for pedestrians ")
  f3.show()
  f4 = plt.figure(4)
  plt.plot(list(acc_val_train_t),marker = 'o')
  plt.xlabel("epochs")
  plt.ylabel("Train map value ")
  plt.title(" Train map Curve for traffic lights ")
  f4.show()
  f5 = plt.figure(5)
  plt.plot(list(acc_val_train_v),marker = 'o')
  plt.xlabel("epochs")
  plt.ylabel("Train map value ")
  plt.title(" Train map Curve for vehicles ")
  f5.show()
  plt.show()
#   raw_input()
  
  print("Epoch %d/%d" % (epoch+1, num_epochs))

"""# Test your network

Testing the network on Unseen images
"""

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

with torch.no_grad():
    for data, target in test_loader:
        data, target = data.cuda(), target.cuda()
        output = net(data)
        loss = criterion(output,target)
        break

# train_dataset = HW2TrainDataset(None)
# image,label = train_dataset.__getitem__(0)
# print(image.shape)

image = data.type(torch.IntTensor).numpy()
image = image[0]
image = np.transpose(image,(1,2,0))
fig,ax = plt.subplots(1)
fig1,ax1 = plt.subplots(1) 
fig1,ax2 = plt.subplots(1)


objectness = (target[:,0]==1.0).type(torch.FloatTensor).cuda()
label = output.cpu().numpy()

label = label[0]


ax1.imshow(image)
for i in range(8):
  for j in range(8):
    if label[0][i][j]>0.0:
      if label[5][i][j]>0.0:
#         print("creting bounding box for a pedestrian")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 -width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect1 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='r',facecolor='none')
        ax1.add_patch(rect1)
      if label[6][i][j]>0.0:
#         print("creting bounding box for a traffic light")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect2 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='b',facecolor='none')
        ax1.add_patch(rect2)
      if label[7][i][j]>0.0:
#         print("creting bounding box for a car")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect3 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='g',facecolor='none')
        ax1.add_patch(rect3)


objectness = (label[0]>0.6).astype(int)
label[1] = objectness*label[1]
label[2] = objectness*label[2]
label[3] = objectness*label[3]
label[4] = objectness*label[4]
label[5] = objectness*label[5]
label[6] = objectness*label[6]
label[7] = objectness*label[7]


for i in range(8):
  for j in range(8):
    max_val = max(label[5][i][j],label[6][i][j],label[7][i][j])
    if label[5][i][j] != max_val:
      label[5][i][j] = 0
    if label[6][i][j] != max_val:
      label[6][i][j] = 0
    if label[7][i][j] != max_val:
      label[7][i][j] = 0

ax2.imshow(image)
for i in range(8):
  for j in range(8):
    if label[0][i][j]>0.0:
      if label[5][i][j]>0.0:
#         print("creting bounding box for a pedestrian")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 -width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect1 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='r',facecolor='none')
        ax2.add_patch(rect1)
      if label[6][i][j]>0.0:
#         print("creting bounding box for a traffic light")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect2 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='b',facecolor='none')
        ax2.add_patch(rect2)
      if label[7][i][j]>0.0:
#         print("creting bounding box for a car")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect3 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='g',facecolor='none')
        ax2.add_patch(rect3)

        
for c in range(5,8):
  for i in range(8):
    for j in range(8):
      if(label[c][i][j]==0):
        continue
      axmin = label[1][i][j]*16 + 16*j - (label[3][i][j]*128)/2
      axmax = label[1][i][j]*16 + 16*j + (label[3][i][j]*128)/2
      aymin = label[2][i][j]*16 + 16*i - (label[4][i][j]*128)/2
      aymax = label[2][i][j]*16 + 16*i + (label[4][i][j]*128)/2
      awidth = label[3][i][j]*128
      aheight = label[4][i][j]*128
      aarea = awidth*aheight

      for p in range(8):
        for q in range(8):
          if(label[c][p][q]==0):
            continue
          if(p!=i and q!=j):
            bxmin = label[1][p][q]*16 + 16*q - (label[3][p][q]*128)/2
            bxmax = label[1][p][q]*16 + 16*q + (label[3][p][q]*128)/2
            bymin = label[2][p][q]*16 + 16*p - (label[4][p][q]*128)/2
            bymax = label[2][p][q]*16 + 16*p + (label[4][p][q]*128)/2
            bwidth = label[3][p][q]*128
            bheight = label[4][p][q]*128
            barea = bwidth*bheight

            aibw = max(0,min(axmax,bxmax)-max(axmin,bxmin))
            aibh = max(0,min(aymax,bymax)-max(aymin,bymin))
            aib = aibw*aibh
            aub = aarea + barea - aib 
            iou = aib/aub

            if iou > 0.5:
              if label[c][i][j]>label[c][p][q]:
                label[0][p][q] = 0
              elif label[c][i][j]<label[c][p][q]:
                label[0][i][j] = 0
              
            
ax.imshow(image)
for i in range(8):
  for j in range(8):
    if label[0][i][j]>0.6:
      if label[5][i][j]>0.5:
#         print("creting bounding box for a pedestrian")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 -width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect1 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='r',facecolor='none')
        ax.add_patch(rect1)
      if label[6][i][j]>0.5:
#         print("creting bounding box for a traffic light")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect2 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='b',facecolor='none')
        ax.add_patch(rect2)
      if label[7][i][j]>0.5:
#         print("creting bounding box for a car")
        width = label[3][i][j]*128
        height = label[4][i][j]*128
        x_coord = label[1][i][j]*16 + j*16 - width/2
        y_coord = label[2][i][j]*16 + i*16 - height/2
        rect3 = patches.Rectangle((x_coord,y_coord),width,height,linewidth=1,edgecolor='g',facecolor='none')
        ax.add_patch(rect3)
        
        
plt.show()